{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim   # for geocoding\n",
    "import numpy as np                      # for numerical computations\n",
    "import folium                           # for map plotting\n",
    "\n",
    "# List of names of the cities we have Airbnb data for\n",
    "city_names = [\"Amsterdam\", \"Athens\", \"Barcelona\", \"Berlin\", \"Budapest\", \"Lisbon\", \"London\", \"Paris\", \"Rome\", \"Vienna\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function generates a list of coordinates around a city in order to cover the area\n",
    "def generar_coordenades(ciutat, num_punts=400):\n",
    "    \"\"\"\n",
    "    Genera un conjunt de coordenades al voltant d'una ciutat.\n",
    "\n",
    "    input:\n",
    "    ciutat: string amb el nom de la ciutat\n",
    "    num_punts: número de punts a generar al voltant de la ciutat\n",
    "\n",
    "    output:\n",
    "    coordenades: llista de tuples amb les coordenades (lat, lon) dels punts generats\n",
    "    \"\"\"\n",
    "    geolocator = Nominatim(user_agent=\"gia-bda\")\n",
    "    location = geolocator.geocode(ciutat)\n",
    "    lat, lon = location.latitude, location.longitude\n",
    "    \n",
    "    dist_lat = np.linspace(-0.08, 0.08, int(np.sqrt(num_punts)))\n",
    "    dist_lon = np.linspace(-0.08, 0.08, int(np.sqrt(num_punts)))\n",
    "    \n",
    "    coordenades = []\n",
    "    for dlat in dist_lat:\n",
    "        for dlon in dist_lon:\n",
    "            coordenades.append((lat + dlat, lon + dlon))\n",
    "    \n",
    "    return coordenades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generant les coordenades per a Amsterdam.\n",
      "Generant les coordenades per a Athens.\n",
      "Generant les coordenades per a Barcelona.\n",
      "Generant les coordenades per a Berlin.\n",
      "Generant les coordenades per a Budapest.\n",
      "Generant les coordenades per a Lisbon.\n",
      "Generant les coordenades per a London.\n",
      "Generant les coordenades per a Paris.\n",
      "Generant les coordenades per a Rome.\n",
      "Generant les coordenades per a Vienna.\n"
     ]
    }
   ],
   "source": [
    "city_coords = {}\n",
    "for city in city_names:\n",
    "    print(f\"Generant les coordenades per a {city}.\")\n",
    "    city_coords[city] = generar_coordenades(city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can visualize the maps of each city in order to see if it actually covers the whole city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of the generated coordinates\n",
    "visualitzar = False\n",
    "if visualitzar:\n",
    "    for city, ll_coords in city_coords.items():\n",
    "        # Create a map\n",
    "        city_map = folium.Map(location=ll_coords[0], zoom_start=13)\n",
    "        # Add the markers\n",
    "        for coord in ll_coords:\n",
    "            folium.Marker(coord).add_to(city_map)\n",
    "        # Save the map\n",
    "        city_map.save(f\"maps/{city}_map.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openmeteo_requests\n",
    "\n",
    "import requests_cache\n",
    "import pandas as pd\n",
    "from retry_requests import retry\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the Open-Meteo API client with cache and retry on error\n",
    "cache_session = requests_cache.CachedSession('.cache', expire_after = 3600)\n",
    "retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
    "openmeteo = openmeteo_requests.Client(session = retry_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make a function to get all the data of each point in the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_weather(city, ll_coords):\n",
    "\n",
    "    dataframe = pd.DataFrame()\n",
    "\n",
    "    for lat, lon in tqdm(ll_coords, desc=f\"Processing {city}\"):\n",
    "\n",
    "        # Make sure all required weather variables are listed here\n",
    "        # The order of variables in hourly or daily is important to assign them correctly below\n",
    "        url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "        params = {\n",
    "            \"latitude\": lat,\n",
    "            \"longitude\": lon,\n",
    "            \"hourly\": [\"temperature_2m\", \"relative_humidity_2m\", \"precipitation_probability\", \"precipitation\", \"weather_code\", \"cloud_cover\", \"cloud_cover_low\", \"cloud_cover_mid\", \"cloud_cover_high\"],\n",
    "            \"forecast_days\": 16\n",
    "        }\n",
    "        responses = openmeteo.weather_api(url, params=params)\n",
    "\n",
    "        # Process first location. Add a for-loop for multiple locations or weather models\n",
    "        response = responses[0]\n",
    "\n",
    "        # Process hourly data. The order of variables needs to be the same as requested.\n",
    "        hourly = response.Hourly()\n",
    "        hourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()\n",
    "        hourly_relative_humidity_2m = hourly.Variables(1).ValuesAsNumpy()\n",
    "        hourly_precipitation_probability = hourly.Variables(2).ValuesAsNumpy()\n",
    "        hourly_precipitation = hourly.Variables(3).ValuesAsNumpy()\n",
    "        hourly_weather_code = hourly.Variables(4).ValuesAsNumpy()\n",
    "        hourly_cloud_cover = hourly.Variables(5).ValuesAsNumpy()\n",
    "        hourly_cloud_cover_low = hourly.Variables(6).ValuesAsNumpy()\n",
    "        hourly_cloud_cover_mid = hourly.Variables(7).ValuesAsNumpy()\n",
    "        hourly_cloud_cover_high = hourly.Variables(8).ValuesAsNumpy()\n",
    "\n",
    "        hourly_data = {\"date\": pd.date_range(\n",
    "            start = pd.to_datetime(hourly.Time(), unit = \"s\", utc = True),\n",
    "            end = pd.to_datetime(hourly.TimeEnd(), unit = \"s\", utc = True),\n",
    "            freq = pd.Timedelta(seconds = hourly.Interval()),\n",
    "            inclusive = \"left\"\n",
    "        )}\n",
    "        hourly_data[\"temperature_2m\"] = hourly_temperature_2m\n",
    "        hourly_data[\"relative_humidity_2m\"] = hourly_relative_humidity_2m\n",
    "        hourly_data[\"precipitation_probability\"] = hourly_precipitation_probability\n",
    "        hourly_data[\"precipitation\"] = hourly_precipitation\n",
    "        hourly_data[\"weather_code\"] = hourly_weather_code\n",
    "        hourly_data[\"cloud_cover\"] = hourly_cloud_cover\n",
    "        hourly_data[\"cloud_cover_low\"] = hourly_cloud_cover_low\n",
    "        hourly_data[\"cloud_cover_mid\"] = hourly_cloud_cover_mid\n",
    "        hourly_data[\"cloud_cover_high\"] = hourly_cloud_cover_high\n",
    "\n",
    "        hourly_dataframe = pd.DataFrame(data = hourly_data)\n",
    "        hourly_dataframe[\"latitude\"] = lat\n",
    "        hourly_dataframe[\"longitude\"] = lon\n",
    "        hourly_dataframe[\"city\"] = city\n",
    "        dataframe = pd.concat([dataframe, hourly_dataframe])\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Amsterdam: 100%|██████████| 400/400 [00:01<00:00, 344.89it/s]\n",
      "Processing Athens: 100%|██████████| 400/400 [00:00<00:00, 405.29it/s]\n",
      "Processing Barcelona: 100%|██████████| 400/400 [00:01<00:00, 396.75it/s]\n",
      "Processing Berlin: 100%|██████████| 400/400 [00:22<00:00, 17.89it/s]\n",
      "Processing Budapest: 100%|██████████| 400/400 [00:30<00:00, 13.23it/s]\n",
      "Processing Lisbon: 100%|██████████| 400/400 [00:30<00:00, 13.13it/s]\n",
      "Processing London: 100%|██████████| 400/400 [00:29<00:00, 13.76it/s]\n",
      "Processing Paris: 100%|██████████| 400/400 [00:26<00:00, 14.94it/s]\n",
      "Processing Rome: 100%|██████████| 400/400 [00:28<00:00, 14.27it/s]\n",
      "Processing Vienna: 100%|██████████| 400/400 [00:27<00:00, 14.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# For each city and its coordinates, we will check the weather, stopping 1 minute between each city to avoid reaching the API limit\n",
    "df_weather = pd.DataFrame()\n",
    "for city, ll_coords in city_coords.items():\n",
    "    city_weather = check_weather(city, ll_coords)\n",
    "    df_weather = pd.concat([df_weather, city_weather])\n",
    "    # Sleep 1 minute\n",
    "    time.sleep(61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.to_parquet(\"datalake/weather_data.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
